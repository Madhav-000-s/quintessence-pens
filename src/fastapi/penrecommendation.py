# -*- coding: utf-8 -*-
"""PENRECOMMENDATION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ZQnuS4bx7An2pv5IK0hPtDnM_15h0XE
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import cosine_similarity
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import pickle
from typing import List, Dict
import warnings
import gc
warnings.filterwarnings('ignore')

# Memory optimization
tf.config.threading.set_intra_op_parallelism_threads(2)
tf.config.threading.set_inter_op_parallelism_threads(2)

class SyntheticDataGenerator:
    """Generate synthetic data matching EXACT database schema."""

    @staticmethod
    def generate_materials(n=10):
        """Material table: id, name, weight, cost, created_at"""
        materials = []
        material_names = ['Gold', 'Platinum', 'Titanium', 'Stainless Steel', 'Carbon Fiber',
                         'Silver', 'Bronze', 'Aluminum', 'Resin', 'Wood']

        for i in range(n):
            materials.append({
                'id': i + 1,
                'created_at': pd.Timestamp.now(),
                'name': material_names[i],
                'weight': float(np.random.uniform(5, 30)),
                'cost': float(np.random.uniform(10, 200))
            })
        return pd.DataFrame(materials)

    @staticmethod
    def generate_designs(n=8):
        """Design table: design_id, description, font, cost, colour, hex_code"""
        designs = []
        fonts = ['Script', 'Serif', 'Sans-Serif', 'Gothic']
        colors = ['Black', 'Blue', 'Gold', 'Silver', 'Red', 'Green', 'Purple', 'Bronze']

        for i in range(n):
            designs.append({
                'design_id': i + 1,
                'description': f'Design Pattern {i+1}',
                'font': fonts[i % len(fonts)],
                'cost': float(np.random.uniform(20, 100)),
                'colour': colors[i % len(colors)],
                'hex_code': f'#{np.random.randint(0, 0xFFFFFF):06x}'
            })
        return pd.DataFrame(designs)

    @staticmethod
    def generate_coatings(n=6):
        """Coating table: coating_id, colour, hex_code, type"""
        coatings = []
        types = ['Matte', 'Glossy', 'Metallic']
        colors = ['Black', 'Silver', 'Gold', 'Blue', 'Red', 'White']

        for i in range(n):
            coatings.append({
                'coating_id': i + 1,
                'colour': colors[i % len(colors)],
                'hex_code': f'#{np.random.randint(0, 0xFFFFFF):06x}',
                'type': types[i % len(types)]
            })
        return pd.DataFrame(coatings)

    @staticmethod
    def generate_ink_configs(n=10):
        """InkConfig table: ink_type_id, type_name, description, color_name, hexcode, cost"""
        inks = []
        colors = ['Black', 'Blue', 'Royal Blue', 'Red', 'Green', 'Purple', 'Brown', 'Turquoise', 'Orange', 'Pink']

        for i in range(n):
            inks.append({
                'ink_type_id': i + 1,
                'type_name': f'Ink Type {i+1}',
                'description': f'Premium ink type {i+1}',
                'color_name': colors[i % len(colors)],
                'hexcode': f'#{np.random.randint(0, 0xFFFFFF):06x}',
                'cost': float(np.random.uniform(5, 30))
            })
        return pd.DataFrame(inks)

    @staticmethod
    def generate_nib_configs(n=12):
        """NibConfig table: nibtype_id, description, size, material_id, design_id, cost"""
        nibs = []
        sizes = ['Extra Fine', 'Fine', 'Medium', 'Broad', 'Stub']

        for i in range(n):
            nibs.append({
                'nibtype_id': i + 1,
                'description': f'Nib Type {i+1}',
                'size': sizes[i % len(sizes)],
                'material_id': (i % 10) + 1,
                'design_id': (i % 8) + 1,
                'cost': float(np.random.uniform(30, 150))
            })
        return pd.DataFrame(nibs)

    @staticmethod
    def generate_barrel_configs(n=15):
        """BarrelConfig table: barrel_id, design_id, engraving_id, grip_type, coating_id, cost, shape, description, material_id"""
        barrels = []
        shapes = ['Cylindrical', 'Tapered', 'Curved', 'Hexagonal', 'Octagonal']
        grip_types = ['Smooth', 'Textured', 'Grooved']

        for i in range(n):
            barrels.append({
                'barrel_id': i + 1,
                'design_id': (i % 8) + 1,
                'engraving_id': (i % 12) + 1,
                'grip_type': grip_types[i % len(grip_types)],
                'coating_id': (i % 6) + 1,
                'cost': float(np.random.uniform(50, 200)),
                'shape': shapes[i % len(shapes)],
                'description': f'Barrel Design {i+1}',
                'material_id': (i % 10) + 1
            })
        return pd.DataFrame(barrels)

    @staticmethod
    def generate_cap_configs(n=12):
        """CapConfig table: cap_type_id, description, material_id, design_id, engraving_id, clip_design_id, coating_id, cost"""
        caps = []

        for i in range(n):
            caps.append({
                'cap_type_id': i + 1,
                'description': f'Cap Type {i+1}',
                'material_id': (i % 10) + 1,
                'design_id': (i % 8) + 1,
                'engraving_id': (i % 12) + 1,
                'clip_design_id': (i % 8) + 1,
                'coating_id': (i % 6) + 1,
                'cost': float(np.random.uniform(30, 120))
            })
        return pd.DataFrame(caps)

    @staticmethod
    def generate_engravings(n=12):
        """Engravings table: engraving_id, font, type_name, description, material_id, cost"""
        engravings = []
        fonts = ['Script', 'Block', 'Cursive', 'Gothic', 'Modern']
        types = ['Laser', 'Hand', 'Machine', 'Chemical']

        for i in range(n):
            engravings.append({
                'engraving_id': i + 1,
                'font': fonts[i % len(fonts)],
                'type_name': types[i % len(types)],
                'description': f'Engraving Style {i+1}',
                'material_id': (i % 10) + 1,
                'cost': float(np.random.uniform(10, 80))
            })
        return pd.DataFrame(engravings)

    @staticmethod
    def generate_pens(n=50):
        """Pen table: pen_id, pentype, nibtype_id, ink_type_id, cap_type_id, barrel_id, cost"""
        pens = []
        pen_types = ['Fountain', 'Rollerball', 'Ballpoint']

        for i in range(n):
            pens.append({
                'pen_id': i + 1,
                'pentype': pen_types[i % len(pen_types)],
                'nibtype_id': (i % 12) + 1,
                'ink_type_id': (i % 10) + 1,
                'cap_type_id': (i % 12) + 1,
                'barrel_id': (i % 15) + 1,
                'cost': float(np.random.uniform(100, 500))
            })
        return pd.DataFrame(pens)

    @staticmethod
    def generate_user_interactions(n_users=500, n_pens=50):
        """UserPenInteractions table: user_id, pen_id, rating"""
        interactions = []

        for user_id in range(1, n_users + 1):
            n_interactions = np.random.randint(3, 12)
            pen_ids = np.random.choice(n_pens, n_interactions, replace=False) + 1

            for pen_id in pen_ids:
                interactions.append({
                    'user_id': user_id,
                    'pen_id': int(pen_id),
                    'rating': float(np.random.uniform(3, 5))
                })

        return pd.DataFrame(interactions)


class PenRecommendationSystem:
    """Memory-optimized recommendation system with EXACT schema compliance."""

    def __init__(self):
        self.user_encoder = LabelEncoder()
        self.pen_encoder = LabelEncoder()
        self.scaler = StandardScaler()
        self.pca = PCA(n_components=5)
        self.model = None
        self.pen_features = None
        self.association_rules_df = None
        self.pen_similarity_matrix = None

    def prepare_pen_features(self, pens_df: pd.DataFrame,
                            ink_config_df: pd.DataFrame,
                            barrel_config_df: pd.DataFrame,
                            cap_config_df: pd.DataFrame,
                            nib_config_df: pd.DataFrame) -> pd.DataFrame:
        """
        Prepare complete pen features maintaining ALL original columns.
        Returns DataFrame with ALL columns from each table.
        """
        pen_features = pens_df.copy()

        # Merge InkConfig - ALL columns
        ink_features = ink_config_df.rename(columns={
            'type_name': 'ink_type_name',
            'description': 'ink_description',
            'color_name': 'ink_color_name',
            'hexcode': 'ink_hexcode',
            'cost': 'ink_cost'
        })
        pen_features = pen_features.merge(ink_features, on='ink_type_id', how='left')

        # Merge BarrelConfig - ALL columns
        barrel_features = barrel_config_df.rename(columns={
            'design_id': 'barrel_design_id',
            'engraving_id': 'barrel_engraving_id',
            'material_id': 'barrel_material_id',
            'coating_id': 'barrel_coating_id',
            'cost': 'barrel_cost',
            'shape': 'barrel_shape',
            'description': 'barrel_description',
            'grip_type': 'barrel_grip_type'
        })
        pen_features = pen_features.merge(barrel_features, on='barrel_id', how='left')

        # Merge CapConfig - ALL columns
        cap_features = cap_config_df.rename(columns={
            'description': 'cap_description',
            'material_id': 'cap_material_id',
            'design_id': 'cap_design_id',
            'engraving_id': 'cap_engraving_id',
            'clip_design_id': 'cap_clip_design_id',
            'coating_id': 'cap_coating_id',
            'cost': 'cap_cost'
        })
        pen_features = pen_features.merge(cap_features, on='cap_type_id', how='left')

        # Merge NibConfig - ALL columns
        nib_features = nib_config_df.rename(columns={
            'description': 'nib_description',
            'size': 'nib_size',
            'material_id': 'nib_material_id',
            'design_id': 'nib_design_id',
            'cost': 'nib_cost'
        })
        pen_features = pen_features.merge(nib_features, on='nibtype_id', how='left')

        # Calculate total cost
        pen_features['total_cost'] = (
            pen_features['cost'] +
            pen_features['ink_cost'].fillna(0) +
            pen_features['barrel_cost'].fillna(0) +
            pen_features['cap_cost'].fillna(0) +
            pen_features['nib_cost'].fillna(0)
        )

        return pen_features

    def build_neural_cf_model(self, n_users: int, n_pens: int, embedding_dim: int = 16):
        """Build lightweight collaborative filtering model."""
        user_input = layers.Input(shape=(1,), name='user_input')
        user_embedding = layers.Embedding(n_users, embedding_dim)(user_input)
        user_vec = layers.Flatten()(user_embedding)

        pen_input = layers.Input(shape=(1,), name='pen_input')
        pen_embedding = layers.Embedding(n_pens, embedding_dim)(pen_input)
        pen_vec = layers.Flatten()(pen_embedding)

        concat = layers.Concatenate()([user_vec, pen_vec])
        dense1 = layers.Dense(32, activation='relu')(concat)
        dropout1 = layers.Dropout(0.2)(dense1)
        dense2 = layers.Dense(16, activation='relu')(dropout1)
        output = layers.Dense(1, activation='sigmoid')(dense2)

        model = keras.Model(inputs=[user_input, pen_input], outputs=output)
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

        return model

    def train_collaborative_filtering(self, user_interactions_df: pd.DataFrame,
                                     epochs: int = 15, batch_size: int = 512):
        """Train collaborative filtering model."""
        user_interactions_df['user_encoded'] = self.user_encoder.fit_transform(
            user_interactions_df['user_id'])
        user_interactions_df['pen_encoded'] = self.pen_encoder.fit_transform(
            user_interactions_df['pen_id'])

        n_users = user_interactions_df['user_encoded'].nunique()
        n_pens = user_interactions_df['pen_encoded'].nunique()

        self.model = self.build_neural_cf_model(n_users, n_pens)

        X_user = user_interactions_df['user_encoded'].values
        X_pen = user_interactions_df['pen_encoded'].values
        y = user_interactions_df['rating'].values / 5.0

        history = self.model.fit(
            [X_user, X_pen], y,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=0.15,
            verbose=0
        )

        return history

    def compute_content_similarity(self, pen_features_df: pd.DataFrame):
        """Compute content-based similarity."""
        numeric_cols = ['cost', 'total_cost', 'ink_cost', 'barrel_cost', 'cap_cost', 'nib_cost']
        numeric_features = pen_features_df[numeric_cols].fillna(0)

        scaled_features = self.scaler.fit_transform(numeric_features)
        reduced_features = self.pca.fit_transform(scaled_features)

        self.pen_similarity_matrix = cosine_similarity(reduced_features)
        self.pen_features = pen_features_df

        del scaled_features, reduced_features
        gc.collect()

        return self.pen_similarity_matrix

    def mine_association_rules(self, user_transactions_df: pd.DataFrame, min_support: float = 0.02):
        """Mine association rules using Apriori."""
        transactions = user_transactions_df.groupby('user_id')['pen_id'].apply(list).values

        te = TransactionEncoder()
        te_ary = te.fit(transactions).transform(transactions)
        df_encoded = pd.DataFrame(te_ary, columns=te.columns_)

        try:
            frequent_itemsets = apriori(df_encoded, min_support=min_support, use_colnames=True, low_memory=True)

            if len(frequent_itemsets) > 0:
                rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.3)
                self.association_rules_df = rules
                return rules
        except:
            pass

        return None

    def get_hybrid_recommendations(self, user_id: int,
                                  visited_pen_ids: List[int],
                                  top_n: int = 10) -> List[Dict]:
        """
        Get recommendations with COMPLETE pen information from ALL tables.
        Returns: List of dictionaries with ALL original table columns.
        """
        recommendations_scores = {}

        # 1. Collaborative Filtering
        if self.model and user_id in self.user_encoder.classes_:
            user_encoded = self.user_encoder.transform([user_id])[0]
            all_pens = np.arange(len(self.pen_encoder.classes_))
            user_array = np.full(len(all_pens), user_encoded)

            cf_scores = self.model.predict([user_array, all_pens], verbose=0, batch_size=128).flatten()

            for pen_idx, score in enumerate(cf_scores):
                pen_id = self.pen_encoder.inverse_transform([pen_idx])[0]
                if pen_id not in visited_pen_ids:
                    recommendations_scores[pen_id] = 0.5 * score

        # 2. Content-Based Filtering
        if self.pen_similarity_matrix is not None and visited_pen_ids:
            for visited_pen_id in visited_pen_ids:
                if visited_pen_id in self.pen_features['pen_id'].values:
                    pen_idx = self.pen_features[self.pen_features['pen_id'] == visited_pen_id].index[0]
                    similar_pens = self.pen_similarity_matrix[pen_idx]

                    for idx, score in enumerate(similar_pens):
                        candidate_pen_id = self.pen_features.iloc[idx]['pen_id']
                        if candidate_pen_id not in visited_pen_ids:
                            if candidate_pen_id in recommendations_scores:
                                recommendations_scores[candidate_pen_id] += 0.5 * score / len(visited_pen_ids)
                            else:
                                recommendations_scores[candidate_pen_id] = 0.5 * score / len(visited_pen_ids)

        # Sort and get top N
        sorted_recs = sorted(recommendations_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]

        # Return COMPLETE pen information with ALL table columns
        result = []
        for pen_id, score in sorted_recs:
            pen_info = self.pen_features[self.pen_features['pen_id'] == pen_id].iloc[0].to_dict()
            pen_info['recommendation_score'] = float(score)
            result.append(pen_info)

        return result

    def save_model(self, filepath='pen_recommender'):
        """Save model efficiently."""
        if self.model:
            self.model.save(f"{filepath}.keras", save_format='keras')

        # Save only essential metadata, keep full pen_features
        metadata = {
            'user_encoder': self.user_encoder,
            'pen_encoder': self.pen_encoder,
            'scaler': self.scaler,
            'pca': self.pca,
            'pen_features': self.pen_features.to_dict('records'),
            'similarity_matrix': self.pen_similarity_matrix.astype(np.float16)
        }

        with open(f"{filepath}_meta.pkl", 'wb') as f:
            pickle.dump(metadata, f, protocol=4)

    def load_model(self, filepath='pen_recommender'):
        """Load model."""
        self.model = keras.models.load_model(f"{filepath}.keras")

        with open(f"{filepath}_meta.pkl", 'rb') as f:
            metadata = pickle.load(f)
            self.user_encoder = metadata['user_encoder']
            self.pen_encoder = metadata['pen_encoder']
            self.scaler = metadata['scaler']
            self.pca = metadata['pca']
            self.pen_features = pd.DataFrame(metadata['pen_features'])
            self.pen_similarity_matrix = metadata['similarity_matrix'].astype(np.float32)

# Main execution
if __name__ == "__main__":
    print("="*80)
    print("LUXURY PEN RECOMMENDATION SYSTEM - EXACT SCHEMA COMPLIANCE")
    print("="*80)

    # Generate data matching EXACT database schema
    print("\n1. Generating data with exact schema...")
    gen = SyntheticDataGenerator()

    materials_df = gen.generate_materials(10)
    designs_df = gen.generate_designs(8)
    coatings_df = gen.generate_coatings(6)
    ink_configs_df = gen.generate_ink_configs(10)
    nib_configs_df = gen.generate_nib_configs(12)
    barrel_configs_df = gen.generate_barrel_configs(15)
    cap_configs_df = gen.generate_cap_configs(12)
    engravings_df = gen.generate_engravings(12)
    pens_df = gen.generate_pens(50)
    user_interactions_df = gen.generate_user_interactions(500, 50)

    print(f"   ✓ Generated complete database schema")
    print(f"   ✓ {len(pens_df)} pens | {len(user_interactions_df)} interactions")

    # Train system
    print("\n2. Training system...")
    recommender = PenRecommendationSystem()

    pen_features = recommender.prepare_pen_features(
        pens_df, ink_configs_df, barrel_configs_df, cap_configs_df, nib_configs_df)

    print(f"   ✓ Pen features prepared: {len(pen_features.columns)} columns")

    history = recommender.train_collaborative_filtering(user_interactions_df, epochs=15)
    print(f"   ✓ CF trained - Accuracy: {history.history['accuracy'][-1]:.4f}")

    recommender.compute_content_similarity(pen_features)
    print("   ✓ Content similarity computed")

    rules = recommender.mine_association_rules(user_interactions_df)
    print(f"   ✓ Association rules: {len(rules) if rules is not None else 0}")

    # Save model
    recommender.save_model('pen_recommender')
    print("   ✓ Model saved")

    # Test with FULL output
    print("\n" + "="*80)
    print("TESTING: 10 CASES WITH COMPLETE TABLE DATA")
    print("="*80)

    test_users = np.random.choice(user_interactions_df['user_id'].unique(), 10, replace=False)

    for i, user_id in enumerate(test_users, 1):
        user_history = user_interactions_df[user_interactions_df['user_id'] == user_id]
        visited_pens = user_history['pen_id'].tolist()[:3]

        print(f"\n{'='*80}")
        print(f"TEST {i}: User {user_id}")
        print(f"{'='*80}")
        print(f"Visited: {visited_pens}")

        recommendations = recommender.get_hybrid_recommendations(user_id, visited_pens, top_n=3)

        for j, rec in enumerate(recommendations, 1):
            print(f"\n  Recommendation {j}:")
            print(f"    Pen ID: {rec['pen_id']} | Type: {rec['pentype']}")
            print(f"    Components:")
            print(f"      - Ink: Type#{rec['ink_type_id']} | {rec['ink_color_name']} | ${rec['ink_cost']:.2f}")
            print(f"      - Barrel: ID#{rec['barrel_id']} | {rec['barrel_shape']} | ${rec['barrel_cost']:.2f}")
            print(f"      - Cap: Type#{rec['cap_type_id']} | ${rec['cap_cost']:.2f}")
            print(f"      - Nib: Type#{rec['nibtype_id']} | {rec['nib_size']} | ${rec['nib_cost']:.2f}")
            print(f"    Total Cost: ${rec['total_cost']:.2f}")
            print(f"    Match Score: {rec['recommendation_score']:.4f}")

    print("\n" + "="*80)
    print("✅ SYSTEM READY - ALL TABLE COLUMNS PRESERVED")
    print("="*80)
